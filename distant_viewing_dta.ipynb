{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seitenspiegel-Analyse am DTA OCR Korpus\n",
    "\n",
    "Ziel des vorliegenden Projekts ist es, das [DTA-Kernkorpus](https://deutschestextarchiv.de) für typographische Analysen zu nutzen. Im Spezifischen geht es um den Satzspiegel: *Wohin wurden auf einer Buchseite die Buchstaben gedruckt?* In Anlehnung an den Begriff des *distant reading* kann hier von *distant viewing* gesprochen werden.\n",
    "\n",
    "Datengrundlage sind die XML-Daten aus dem OCR-Workflow der ersten Projektphase des DTA (2007–2010), die mit OCR erfasst, nachkorrigiert und in TEI P5 kodiert wurden. Es handelt sich um 199 Texte des *Kernkorpus*. Da das DTA seinen \"Fokus\", wie das Projektteam schreibt, auf die \"Textdaten\" legen möchte (\"und die Verknüpfung zu den Faksimiledaten über die Seitenzuordnung ausreichend ist\"), wurde dieser arbeitsaufwändige Workflow nicht mehr weiter geführt. Die entsprechenden Daten werden auf deren [Website](https://deutschestextarchiv.de/download#ocr) zur Verfügung gestellt. Die von mir am 30.1.2020 heruntergeladenen Daten datieren auf den 6.11.2013.\n",
    "\n",
    "In den TEI-Daten des DTA werden jedem Buchstaben konkrete Koordinate nach folgendem Schema zugewiesen:\n",
    "\n",
    "```xml\n",
    "\t<pb facs=\"#f0001\"/>\n",
    "\t[…]\n",
    "\t<c ulx=\"44\" uly=\"954\" lrx=\"103\" lry=\"1030\" rendition=\"#c #b\" xml:id=\"c1\">R</c>\n",
    "\t<c ulx=\"102\" uly=\"974\" lrx=\"139\" lry=\"1030\" rendition=\"#c #b\" xml:id=\"c2\">u</c>\n",
    "    <lb/>\n",
    "\t[…]\n",
    "```\n",
    "\n",
    "Ausgezeichnet sind in diesen Daten die TEI-*front*-, -*body*- und -*back*-Umgebungen (hier kommt nur der *body* in den Blick) und *framework*-Bereiche, das heißt beispielsweise Seitenzahlen, die hier nicht berücksichtigt werden.\n",
    "\n",
    "Nota bene: Die Koordinaten beziehen sich weder auf die online dargestellten Faksimiles noch auf die Bilddaten der jeweiligen Urheber-Institution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pakete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- encoding: utf8 -*-\n",
    "\n",
    "# Pakete importieren\n",
    "import re, glob # Regex, Global\n",
    "from bs4 import BeautifulSoup # XML Parser\n",
    "from PIL import Image, ImageDraw # Python Imaging Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auslesen der Daten aus den DTA-XML-Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sicherheitsvorkehrung:\n",
    "eingabe = input(\"Das starten dieses Abschnitts setzt einen großen Prozess in Gang und überschreibt womöglich bestehende Daten. Sicher? Y/N\")\n",
    "if eingabe == \"N\":\n",
    "    import sys\n",
    "    sys.exit()\n",
    "elif eingabe == \"Y\":\n",
    "    pass\n",
    "else:\n",
    "    import sys\n",
    "    sys.exit()\n",
    "\n",
    "# Programm:\n",
    "filepaths = \"dta_ocr_texte_2013-11-06/*.ready.xml\"\n",
    "\n",
    "for filepath in sorted(glob.glob(filepaths)):\n",
    "    filename = filepath[25:]\n",
    "\n",
    "    with open('Satzspiegel_DatenBilder/'+filename+'.csv', 'w', encoding='utf-8') as tempfh:\n",
    "        tempfh.write('')\n",
    "    \n",
    "    # Filecontent\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as fh:\n",
    "        print(\"open file… \" + filepath)\n",
    "        bodysoup = BeautifulSoup(fh.read(), \"lxml-xml\").body # nur body-Bereich auswählen\n",
    "        for fw in bodysoup.find_all(\"fw\"): # Framework-Elemente entfernen\n",
    "            fw.decompose()\n",
    "        for c in bodysoup.find_all(\"c\"): # c-Elemente finden\n",
    "            if (\"ulx\" or \"uly\" or \"lrx\" or \"lry\") in c.attrs: # nur c-Elemente mit Koordinaten\n",
    "                with open('Satzspiegel_DatenBilder/'+filename+'.csv', 'a', encoding='utf-8') as tempfh: # Koordinaten in Datei schreiben\n",
    "                    tempfh.write( \n",
    "                        c['ulx']+','+\n",
    "                        c['uly']+','+\n",
    "                        c['lrx']+','+\n",
    "                        c['lry']+'\\n' )\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeichnen der ausgelesenen Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = 'Satzspiegel_DatenBilder/*.csv'\n",
    "for filepath in sorted(glob.glob(filepaths)):\n",
    "    with open(filepath, 'r', encoding='utf-8') as fh:\n",
    "        print(\"reading\", filepath)\n",
    "        file = fh.read()\n",
    "        \n",
    "        # Error counter for stats:\n",
    "        errorc_x = 0\n",
    "        errorc_y = 0\n",
    "        \n",
    "        im = Image.new('1', (3000, 3400), color=(1))\n",
    "        draw = ImageDraw.Draw(im)\n",
    "        for line in file.split(\"\\n\"):\n",
    "            \n",
    "            if line == \"\": # am Ende jeder Datei ist eine Leerzeile: diese überspringen\n",
    "                continue\n",
    "            \n",
    "            coord = line.split(\",\") # Zeile splitten in Koordinaten\n",
    "\n",
    "            ulx = int(coord[0])\n",
    "            uly = int(coord[1])\n",
    "            lrx = int(coord[2])\n",
    "            lry = int(coord[3])\n",
    "            \n",
    "            #hier:\n",
    "            if (ulx <= 0) or (ulx >= 3000) or (lrx <= 0) or (lrx >= 3000): # X-Koordinaten überprüfen / überspringen\n",
    "                #print(\"- X-coord. out of window: \", coord)\n",
    "                errorc_x += 1\n",
    "                continue\n",
    "            if (uly <= 0) or (uly >= 3400) or (lry <= 0) or (lry >= 3400): # Y-Koordinaten überprüfen / überspringen\n",
    "                #print(\"- Y-coord. out of window: \", coord)\n",
    "                errorc_y += 1\n",
    "                continue\n",
    "\n",
    "            try: # Zeichnen:\n",
    "                draw.rectangle( (ulx, uly, lrx, lry), fill=(0))\n",
    "            except: # Error-Handling:\n",
    "                print(\"- error in file/line:\", filepath, line)\n",
    "\n",
    "        im.save(filepath+'.jpg', quality=50)\n",
    "        print(\" - error-counter (X/Y-coord.): \"+\n",
    "              str(errorc_x)+\"/\"+str(errorc_y)+\", at \"+str(len(file.split(\"\\n\")))+\" chars\")\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weiterverarbeitung mit bash & imagemagick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bilder runter rechnen, Montage und Animation erstellen:\n",
    "\n",
    "```bash\n",
    "cd Satzspiegel_DatenBilder\n",
    "for file in *.jpg; do convert $file -resize 300x300 ${file##*/}; done\n",
    "FILELIST=*.jpg\n",
    "montage $FILELIST -tile 25x -border 1 -bordercolor black -geometry +0+1 montage.jpg\n",
    "convert -delay 10 *. ../animation.gif\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notizen zur Entscheidung, wieviel Darstellungsfläche gewählt werden soll\n",
    "\n",
    "Die größte 'Fehlerquelle' (d.h. jene Werte, die entweder besonders häufig negativ sind oder unrealistisch hoch) sind die x-Koordinaten (_ulx_ und _lrx_). Siehe folgende Auswertung der *errorc_x* und *errorc_y* Ausgaben.\n",
    "\n",
    "Hier, schmutzigerweise nur per `grep` (dh. inkl. allen c-Koordinaten, auch von *front*, *fw* usw.):\n",
    "\n",
    "```bash\n",
    "grep -Pho '(?<=uly=\")(.+?)(?=\")' dta_ocr_texte_2013-11-06/* > temp\n",
    "sort temp | uniq -c | sort -nr | awk '{ print $2 \",\" $1}' > ulyvalues.csv\n",
    "```\n",
    "\n",
    "## zum ulx-Wert\n",
    "\n",
    "Es gibt 8.746 negative ulx-Koordinaten (von '-9' bis '-1475', im Mittelwert 6 mal), exkl. der Koordinate **'-1'** mit **159.958** Vorkommen. (Einmal gibt es den Wert '-2147483648'.)\n",
    "\n",
    "Es gibt insgesamt 56.372.345 positive Werte. Der häufigste positive Wert ist '816' (57.646 mal).\n",
    "\n",
    "Der Wert '0' kommt 2.712 mal vor. Werte unter 15 gibt es selten (428 mal). Der häufigste Werte über 1.000 ist 1.001 (47.178 mal). Unter 1.000 ist der Mittelwert 805 (20.526.344 mal). Der häufigste Wert über 2.000 ist 2.002 (180 mal). Zwischen 2.000 und dem höchsten Wert 2.265 (außer der Koordinate '10000000') gibt es 22.665 Koordinaten.\n",
    "\n",
    "Ein **Minimumwert von 15** schließt 561 und ein **Maximalwert von 2.200** schließt 841 Werte aus.\n",
    "\n",
    "## zum lrx-Wert\n",
    "\n",
    "Es gibt 8.782 negative lrx-Koordinaten ('-15' bis '-1466', im Mittelwert 6 mal), exkl. der Koordinate **'-1'** mit **116.614** Vorkommen. (Einmal gibt es den Wert '-2147483648'.)\n",
    "\n",
    "Es gibt insgesamt 56.415.653 positive Werte. Der häufigste positive Wert ist '844' (57.613 mal).\n",
    "\n",
    "Der Wert '0' kommt 656 mal vor (und weicht damit erheblich von der 0-Häufigkeit von ulx ab). Werte unter 30 gibt es selten (508 mal). Der häufigste Wert über 1.000 ist 1.001 (48.356 mal). Unter 1.000 ist der Mittelwert 819 (54.575 mal). Der häufigste Wert über 2.000 ist 2.003 (237 mal). Zwischen 2.000 und dem höchsten Wert 2.421 (außer der Koordinate '10000000') gibt es 26.487 Koordinaten.\n",
    "\n",
    "Ein **Minimumwert von 30** schließt 508 und ein **Maximalwert von 2.200** schließt 1.780 Werte aus.\n",
    "\n",
    "## Fazit x-Werte\n",
    "\n",
    "Bei beiden Empfehlungen sind die erheblichen negativen Werte nicht berücksichtigt. Es gälte zu überprüfen, ob eine einfache Umkehrung des Vorzeichens, so dass die Werte positiv werden, eine realistische Möglichkeit ist, ob dieser Fehler bei der Vorverarbeitung geschehen sein kann.\n",
    "\n",
    "## zum lry-Wert\n",
    "\n",
    "Der Wert '-1' kommt sehr häufig (22.251 mal) vor. Als **Maximalwert** würde ich hier **2.500** nehmen, Minimum 0.\n",
    "\n",
    "## zum uly-Wert\n",
    "\n",
    "Der Wert -1 kommt sehr häufig (29.119) vor (hier auch 1.000.000 mit 85 mal und einmal 77.899). Als **Maximalwert** würde ich hier **3.000** nehmen, Minimum 0.\n",
    "\n",
    "# FAZIT\n",
    "\n",
    "Um sicher zu gehen und großräumig abzudecken, auch um mit einem tendenziell quadratischen Format kein Hochkant zu unterstützen wird das Ausgabeformat 3000 x 3400 gewählt. Werte unter 0 und über 3000 bzw. 3400 werden nicht berücksichtigt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
